{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-07T18:30:54.541788Z",
     "start_time": "2024-07-07T18:30:54.191979Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from src.metrics import map_score, mrr_score, ndcg_score, rmse_score\n",
    "from src.models.alternating_least_squares import ALSRecommender\n",
    "from src.utils import train_test_split, to_user_movie_matrix, make_binary_matrix, RatingMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's load the datasets with users info, movies info and users' ratings for movies.\n",
    "\n",
    "Then we split it to training/test subsets by the timestamp."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cdde08a0225832f8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "users = pd.read_table(\"../data/users.dat\", sep=\"::\", names=['UserID', 'Gender', 'Age', 'Occupation', 'Zip-code'], engine='python')\n",
    "\n",
    "movies = pd.read_table(\"../data/movies.dat\", sep=\"::\", names=['MovieID', 'Title', 'Genres'], engine='python', encoding='latin1')\n",
    "\n",
    "ratings = pd.read_table(\"../data/ratings.dat\", sep=\"::\", names=['UserID', 'MovieID', 'Rating', 'Timestamp'], engine='python')\n",
    "ratings['Timestamp'] = pd.to_datetime(ratings['Timestamp'], unit='s')\n",
    "\n",
    "ratings = ratings[ratings['MovieID'].isin(movies['MovieID'])]\n",
    "\n",
    "train_ratings, test_ratings = train_test_split(ratings, 'Timestamp')\n",
    "user_movie_train = to_user_movie_matrix(train_ratings)\n",
    "user_movie_test = to_user_movie_matrix(test_ratings)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-07T18:30:56.885277Z",
     "start_time": "2024-07-07T18:30:54.555555Z"
    }
   },
   "id": "21f85a481665f20a",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, we are going to train our content-based recommender model, which predicts ratings based on the movie features. It takes into account the similarity between the movie, we are going to predict the rating of, and the movies, which were rated by the user before."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c1fcaeb26921129"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = ALSRecommender()\n",
    "model.train(user_movie_train, 10)\n",
    "\n",
    "y_pred = model.predict(make_binary_matrix(user_movie_test.get_rating_matrix()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-07T18:31:22.201480Z",
     "start_time": "2024-07-07T18:30:56.886664Z"
    }
   },
   "id": "51c89898b0f6dfe0",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "Given the predicted ratings and test dataset, we are going to evaluate our model by four metrics:\n",
    "* mean average precision (MAP)\n",
    "* mean reciprocal rank (MRR)\n",
    "* normalized discounted cumulative gain (NDCG)\n",
    "* root mean squared error (RMSE)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ef6ca1dc4ee89b8"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.19645168170058033\n",
      "MRR: 0.47359939864345146\n",
      "NDCG: 0.2863324829777592\n",
      "RMSE: 3.2470191994977236\n"
     ]
    }
   ],
   "source": [
    "map_score_value = map_score(RatingMatrix(user_movie_test.get_rating_matrix()[y_pred.get_users()]), y_pred, top=10)\n",
    "mrr_score_value = mrr_score(RatingMatrix(user_movie_test.get_rating_matrix()[y_pred.get_users()]), y_pred, top=10)\n",
    "ndcg_score_value = ndcg_score(RatingMatrix(user_movie_test.get_rating_matrix()[y_pred.get_users()]), y_pred, top=10)\n",
    "rmse_score_value = rmse_score(RatingMatrix(user_movie_test.get_rating_matrix()[y_pred.get_users()]), y_pred)\n",
    "\n",
    "print(f'MAP: {map_score_value}')\n",
    "print(f'MRR: {mrr_score_value}')\n",
    "print(f'NDCG: {ndcg_score_value}')\n",
    "print(f'RMSE: {rmse_score_value}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-07T18:31:22.950842Z",
     "start_time": "2024-07-07T18:31:22.205429Z"
    }
   },
   "id": "fdc3eccc4b869634",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "A MAP of 0.196 indicates that, on average, about 19.6% of the top-10 recommended items are relevant.\n",
    "\n",
    "An MRR of 0.473 means that, on average, the first relevant item appears between the 1st and 2nd positions in the recommendation list.\n",
    "\n",
    "NDCG measures the quality of the recommendations by considering the position of the relevant items in the list, with higher-ranked items contributing more to the score.\n",
    "\n",
    "RMSE measures the differences between the predicted and actual ratings, which in our case is about 1 and a little bit bigger than baseline"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b1e02b8f76e8ca0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
