{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-14T18:56:54.568220Z",
     "start_time": "2024-06-14T18:56:54.169992Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from src.metrics import map_score, mrr_score, ndcg_score, rmse_score\n",
    "from src.models.mean_rating_baseline import MeanRatingRecommender\n",
    "from src.utils import train_test_split, to_user_movie_matrix, make_binary_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's load the dataset with users' ratings of movies and split it to training/test subsets by the timestamp."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a28cc9493b1446e4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ratings = pd.read_table(\"../data/ratings.dat\", sep=\"::\", names=['UserID', 'MovieID', 'Rating', 'Timestamp'], engine='python')\n",
    "ratings['Timestamp'] = pd.to_datetime(ratings['Timestamp'], unit='s')\n",
    "\n",
    "train_ratings, test_ratings = train_test_split(ratings, 'Timestamp')\n",
    "user_movie_train = to_user_movie_matrix(train_ratings)\n",
    "user_movie_test = to_user_movie_matrix(test_ratings) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T18:56:57.651669Z",
     "start_time": "2024-06-14T18:56:54.569762Z"
    }
   },
   "id": "607df2fa7103d668",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's train the baseline model, which calculates average ratings for each movie and predicts it to any user."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4fa1b51e6d2b1e4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "baseline = MeanRatingRecommender()\n",
    "baseline.train(user_movie_train)\n",
    "\n",
    "y_pred = baseline.predict(make_binary_matrix(user_movie_test.get_rating_matrix()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T18:56:58.951414Z",
     "start_time": "2024-06-14T18:56:57.652409Z"
    }
   },
   "id": "c682e23030484088",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "Given the predicted ratings and test dataset, we are going to evaluate our model by four metrics:\n",
    "* mean average precision (MAP)\n",
    "* mean reciprocal rank (MRR)\n",
    "* normalized discounted cumulative gain (NDCG)\n",
    "* root mean squared error (RMSE)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62515589fd0a9e73"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MAP: 0.2374197184197179\n",
      "Baseline MRR: 0.5521855621855621\n",
      "Baseline NDCG: 0.3459796658181121\n",
      "Baseline RMSE: 487.20774588475194\n"
     ]
    }
   ],
   "source": [
    "map_score_value = map_score(user_movie_test, y_pred, top=10)\n",
    "mrr_score_value = mrr_score(user_movie_test, y_pred, top=10)\n",
    "ndcg_score_value = ndcg_score(user_movie_test, y_pred, top=10)\n",
    "rmse_score_value = rmse_score(user_movie_test, y_pred)\n",
    "\n",
    "print(f'Baseline MAP: {map_score_value}')\n",
    "print(f'Baseline MRR: {mrr_score_value}')\n",
    "print(f'Baseline NDCG: {ndcg_score_value}')\n",
    "print(f'Baseline RMSE: {rmse_score_value}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T18:57:01.046770Z",
     "start_time": "2024-06-14T18:56:58.955351Z"
    }
   },
   "id": "6977dffc0cedbad",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "A MAP of 0.237 indicates that, on average, about 23.7% of the recommended items are relevant.\n",
    "\n",
    "An MRR of 0.552 means that, on average, the first relevant item appears around the 2nd position in the recommendation list. This indicates that users are likely to find relevant items fairly quickly, which is a positive outcome.\n",
    "\n",
    "NDCG measures the quality of the recommendations by considering the position of the relevant items in the list, with higher-ranked items contributing more to the score.\n",
    "\n",
    "RMSE measures the differences between the predicted and actual ratings, which in our case is significant."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d551fc5ae98ee94"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9cdd4c593d47cecf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
